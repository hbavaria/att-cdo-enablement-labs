
# Spark Engine ID 
SPARK_ENGINE_ID="spark825"

# cloud user id / Update with your IBMID, usually your email  
CLOUD_USER_ID = ""

# COS buckets 
HIVE_BUCKET="hive-tor-bucket"
WXD_BUCKET="milvus-tor-bucket"
MILVUS_BUCKET="milvus-tor-bucket"
INPUT_BUCKET="input-data-tor-bucket"

# watsonx data catalogs 
HIVE_CATALOG="hive_catalog"
ICEBERG_CATALOG="iceberg_data"


# watsonx.data schemas -> Update schemas names to add your name and first 3 letter from surname
SCHEMA_DWH_OFFLOAD = "netezza_offload_YourName_First3LettersOfSurname"
SCHEMA_DATA_H = "input_data_hive_YourName_First3LettersOfSurname"
SCHEMA_DATA_I = "clients_schema_YourName_First3LettersOfSurname"


# watsonx.ai ->  Copy from your Reference Note
WATSONX_URL = "https://us-south.ml.cloud.ibm.com"
WATSONX_PROJECT_ID = ""
WATSONX_DEPLOYMENT_SPACE_ID = ""

# parameters for milvus ingestion -> Should not need to change 
SIMILARITY_METRIC="L2"
SENTENCE_TRANSFORMER = "sentence-transformers/all-MiniLM-L6-v2"
TEXT_SPLITTER_CHUNK_SIZE=1000
TEXT_SPLITTER_CHUNK_OVERLAP=200
TEXT_SPLITTER_SEPARATORS='[" \n", "\n"]'
TEXT_REPLACEMENTS='{"âœ”": "ok"}'
TEXT_SPLITTER_TYPE="RecursiveCharacterTextSplitter"